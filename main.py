import os
import json
import pandas as pd
import requests
from geopy.geocoders import Nominatim
from geopy.distance import geodesic
from datetime import date, datetime, timedelta

# --- 1. ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’å–å¾— ---
# GitHub Actionsã®å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã‹ã‚‰å€¤ã‚’å—ã‘å–ã‚Šã¾ã™
PLACE_INPUT = os.environ.get("SEARCH_VENUE", "")
COND_INPUT = os.environ.get("SEARCH_COND", "ç¦ç…™,æœé£Ÿä»˜ã")
RAKUTEN_APP_ID = os.environ.get("RAKUTEN_APP_ID")

# --- 2. ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨åˆæœŸåŒ– ---
def initialize_data():
    # æ¥½å¤©ã‚¨ãƒªã‚¢JSONã®èª­ã¿è¾¼ã¿
    with open("rakuten_area_class.json", "r", encoding="utf-8") as f:
        data = json.load(f)

    records = []
    # largeClasses -> middleClasses -> smallClasses -> detailClasses ã¨æ·±ãæ½œã‚‹
    for large_entry in data["areaClasses"]["largeClasses"]:
        large_class_info = large_entry["largeClass"][0]
        l_code = large_class_info["largeClassCode"]
        l_name = large_class_info["largeClassName"]

        # middleClassesãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        if len(large_entry["largeClass"]) < 2: continue
        
        for middle_entry in large_entry["largeClass"][1]["middleClasses"]:
            middle_class_info = middle_entry["middleClass"][0]
            m_code = middle_class_info["middleClassCode"]
            m_name = middle_class_info["middleClassName"]

            # smallClassesãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            if len(middle_entry["middleClass"]) < 2: continue

            for small_entry in middle_entry["middleClass"][1]["smallClasses"]:
                small_class_info = small_entry["smallClass"][0]
                s_code = small_class_info["smallClassCode"]
                s_name = small_class_info["smallClassName"]

                # detailClassesãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆã“ã“ãŒã‚¨ãƒ©ãƒ¼ã®åŸå› ã§ã—ãŸï¼‰
                # ãƒªã‚¹ãƒˆãŒ2è¦ç´ ä»¥ä¸Šã‚ã‚Šã€ã‹ã¤2è¦ç´ ç›®ã«'detailClasses'ãŒã‚ã‚‹ã‹ç¢ºèª
                if len(small_entry["smallClass"]) >= 2:
                    detail_data = small_entry["smallClass"][1]
                    if "detailClasses" in detail_data:
                        for detail_entry in detail_data["detailClasses"]:
                            d_class = detail_entry["detailClass"]
                            records.append({
                                "largeClassCode": l_code,
                                "middleClassCode": m_code,
                                "smallClassCode": s_code,
                                "detailClassCode": d_class["detailClassCode"],
                                "largeClassName": l_name,
                                "middleClassName": m_name,
                                "smallClassName": s_name,
                                "detailClassName": d_class["detailClassName"]
                            })
                    else:
                        # è©³ç´°ã‚¨ãƒªã‚¢ãŒãªã„å ´åˆã¯ã€å°ã‚¨ãƒªã‚¢ã®æƒ…å ±ã‚’ãã®ã¾ã¾ç™»éŒ²ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
                        records.append({
                            "largeClassCode": l_code, "middleClassCode": m_code,
                            "smallClassCode": s_code, "detailClassCode": "",
                            "largeClassName": l_name, "middleClassName": m_name,
                            "smallClassName": s_name, "detailClassName": s_name
                        })
    
    rakuten_df = pd.DataFrame(records)
    
    # gazetteer-of-japan.csvã®èª­ã¿è¾¼ã¿
    try:
        gaz_df = pd.read_csv("gazetteer-of-japan.csv")[["kanji", "lat", "lng"]]
    except Exception as e:
        print(f"âš ï¸ CSVèª­ã¿è¾¼ã¿è­¦å‘Š: {e}")
        gaz_df = pd.DataFrame(columns=["kanji", "lat", "lng"])

    # ç·¯åº¦çµŒåº¦æƒ…å ±ã®ç´ä»˜ã‘
    def lookup_latlon(detail_name):
        if not detail_name: return None, None
        for name in str(detail_name).split("ãƒ»"):
            match = gaz_df[gaz_df["kanji"] == name]
            if not match.empty:
                return match.iloc[0]["lat"], match.iloc[0]["lng"]
        return None, None

    if not rakuten_df.empty:
        rakuten_df[["latitude", "longitude"]] = rakuten_df["detailClassName"].apply(
            lambda x: pd.Series(lookup_latlon(x))
        )
    
    return rakuten_df, gaz_df

rakuten_df, gaz_df = initialize_data()

# --- 3. æ¤œç´¢ãƒ­ã‚¸ãƒƒã‚¯é–¢æ•° ---

def get_place_address(place_name):
    geolocator = Nominatim(user_agent="rakuten_search_bot")
    try:
        location = geolocator.geocode(place_name + ", Japan", timeout=10)
        return location.address if location else None
    except: return None

def find_nearest_rakuten_area(lat, lon, rakuten_df):
    min_dist, nearest = float("inf"), None
    for _, row in rakuten_df.iterrows():
        if pd.notnull(row["latitude"]):
            dist = geodesic((lat, lon), (row["latitude"], row["longitude"])).km
            if dist < min_dist:
                min_dist, nearest = dist, row.to_dict()
                nearest["matched_string"] = f"{dist:.2f}km"
    return nearest

def main_search(place_name, checkin=None, checkout=None, squeeze_cond=""):
    if not checkin: checkin = date.today().isoformat()
    if not checkout: checkout = (date.today() + timedelta(days=1)).isoformat()

    # --- ãƒ‡ãƒãƒƒã‚°æƒ…å ± ---
    geolocator = Nominatim(user_agent="rakuten_search_bot")
    location = geolocator.geocode(place_name + ", Japan", timeout=10)
    
    if not location:
        print(f"âŒ {place_name} ã®ä½ç½®æƒ…å ±ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        return pd.DataFrame()
    
    print(f"ğŸ“ åº§æ¨™å–å¾—: {place_name} ({location.latitude}, {location.longitude})")
    
    match = find_nearest_rakuten_area(location.latitude, location.longitude, rakuten_df)
    if not match:
        print(f"âŒ è¿‘éš£ã®æ¥½å¤©ã‚¨ãƒªã‚¢ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return pd.DataFrame()
    
    print(f"ğŸ—ºï¸ ã‚¨ãƒªã‚¢åˆ¤å®š: {match['largeClassName']} - {match['middleClassName']} - {match['smallClassName']} ({match['detailClassName']})")
    print(f"ğŸ” è·é›¢: {match['matched_string']}")

    params = {
        "applicationId": RAKUTEN_APP_ID,
        "format": "json",
        "checkinDate": checkin,
        "checkoutDate": checkout,
        "largeClassCode": "japan",
        "middleClassCode": match["middleClassCode"],
        "smallClassCode": match["smallClassCode"],
        "detailClassCode": match["detailClassCode"],
        "squeezeCondition": squeeze_cond,
        "hits": 30
    }

    res = requests.get("https://app.rakuten.co.jp/services/api/Travel/VacantHotelSearch/20170426", params=params)
    
    if res.status_code != 200:
        print(f"âŒ APIã‚¨ãƒ©ãƒ¼: ã‚µãƒ¼ãƒ“ã‚¹å´ã§å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ (Status: {res.status_code})")
        # ã‚¨ãƒ©ãƒ¼è©³ç´°ã‚’è¡¨ç¤º
        err_msg = res.json().get("error_description", "Unknown Error")
        print(f"   ç†ç”±: {err_msg}")
        return pd.DataFrame()

    hotels = res.json().get("hotels", [])
    plans = []
    # ... (ãƒ—ãƒ©ãƒ³è§£æéƒ¨åˆ†ã¯å‰ã®ã‚³ãƒ¼ãƒ‰ã¨åŒã˜) ...
    for h in hotels:
        hotel_info = h["hotel"][0]["hotelBasicInfo"]
        room_info_list = h["hotel"][1].get("roomInfo", [])
        for i in range(0, len(room_info_list), 2):
            basic = room_info_list[i].get("roomBasicInfo", {})
            charge = room_info_list[i+1].get("dailyCharge", {})
            price = charge.get("total")
            if price:
                plans.append({
                    "ä¼šå ´": place_name, "ãƒã‚§ãƒƒã‚¯ã‚¤ãƒ³": checkin, "ãƒ›ãƒ†ãƒ«å": hotel_info["hotelName"],
                    "æ–™é‡‘": int(price), "äºˆç´„URL": basic.get("reserveUrl")
                })
    return pd.DataFrame(plans)

# --- å®Ÿè¡Œå‡¦ç†ã®æœ€å¾Œ ---
all_results = []
# (ä¼šå ´ãƒªã‚¹ãƒˆä½œæˆãªã©ã®å‡¦ç†...)

# æ¤œç´¢å®Ÿè¡Œ
for v in venue_list:
    print(f"\n--- ğŸ” {v['place']} ã®æ¤œç´¢é–‹å§‹ ---")
    res_df = main_search(v["place"], v.get("checkin"), v.get("checkout"), squeeze_cond)
    if not res_df.empty:
        all_results.append(res_df)

# ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ï¼ˆç©ºã§ã‚‚ä½œæˆã™ã‚‹ã‚ˆã†ã«ä¿®æ­£ï¼‰
if all_results:
    final_df = pd.concat(all_results).sort_values("æ–™é‡‘")
    print("\n### ğŸ¨ æ¤œç´¢çµæœä¸€è¦§")
    print(final_df.to_markdown(index=False))
    final_df.to_csv("result.csv", index=False, encoding="utf-8-sig")
else:
    print("\nâŒ æ¡ä»¶ã«åˆã†ç©ºå®¤ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    # ç©ºã®CSVã‚’ä½œæˆã—ã¦Artifactã®ã‚¨ãƒ©ãƒ¼ã‚’é˜²ã
    pd.DataFrame(columns=["ä¼šå ´", "çµæœ"]).to_csv("result.csv", index=False)
