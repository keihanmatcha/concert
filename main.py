import os
import json
import pandas as pd
import requests
from geopy.geocoders import Nominatim
from geopy.distance import geodesic
from datetime import date, datetime, timedelta

# --- 1. ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’å–å¾— ---
# GitHub Actionsã®å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã‹ã‚‰å€¤ã‚’å—ã‘å–ã‚Šã¾ã™
PLACE_INPUT = os.environ.get("SEARCH_VENUE", "")
COND_INPUT = os.environ.get("SEARCH_COND", "ç¦ç…™,æœé£Ÿä»˜ã")
RAKUTEN_APP_ID = os.environ.get("RAKUTEN_APP_ID")

# --- 2. ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨åˆæœŸåŒ– ---
def initialize_data():
    # æ¥½å¤©ã‚¨ãƒªã‚¢JSONã®èª­ã¿è¾¼ã¿
    with open("rakuten_area_class.json", "r", encoding="utf-8") as f:
        data = json.load(f)

    records = []
    # largeClasses -> middleClasses -> smallClasses -> detailClasses ã¨æ·±ãæ½œã‚‹
    for large_entry in data["areaClasses"]["largeClasses"]:
        large_class_info = large_entry["largeClass"][0]
        l_code = large_class_info["largeClassCode"]
        l_name = large_class_info["largeClassName"]

        # middleClassesãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        if len(large_entry["largeClass"]) < 2: continue
        
        for middle_entry in large_entry["largeClass"][1]["middleClasses"]:
            middle_class_info = middle_entry["middleClass"][0]
            m_code = middle_class_info["middleClassCode"]
            m_name = middle_class_info["middleClassName"]

            # smallClassesãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            if len(middle_entry["middleClass"]) < 2: continue

            for small_entry in middle_entry["middleClass"][1]["smallClasses"]:
                small_class_info = small_entry["smallClass"][0]
                s_code = small_class_info["smallClassCode"]
                s_name = small_class_info["smallClassName"]

                # detailClassesãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ï¼ˆã“ã“ãŒã‚¨ãƒ©ãƒ¼ã®åŸå› ã§ã—ãŸï¼‰
                # ãƒªã‚¹ãƒˆãŒ2è¦ç´ ä»¥ä¸Šã‚ã‚Šã€ã‹ã¤2è¦ç´ ç›®ã«'detailClasses'ãŒã‚ã‚‹ã‹ç¢ºèª
                if len(small_entry["smallClass"]) >= 2:
                    detail_data = small_entry["smallClass"][1]
                    if "detailClasses" in detail_data:
                        for detail_entry in detail_data["detailClasses"]:
                            d_class = detail_entry["detailClass"]
                            records.append({
                                "largeClassCode": l_code,
                                "middleClassCode": m_code,
                                "smallClassCode": s_code,
                                "detailClassCode": d_class["detailClassCode"],
                                "largeClassName": l_name,
                                "middleClassName": m_name,
                                "smallClassName": s_name,
                                "detailClassName": d_class["detailClassName"]
                            })
                    else:
                        # è©³ç´°ã‚¨ãƒªã‚¢ãŒãªã„å ´åˆã¯ã€å°ã‚¨ãƒªã‚¢ã®æƒ…å ±ã‚’ãã®ã¾ã¾ç™»éŒ²ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
                        records.append({
                            "largeClassCode": l_code, "middleClassCode": m_code,
                            "smallClassCode": s_code, "detailClassCode": "",
                            "largeClassName": l_name, "middleClassName": m_name,
                            "smallClassName": s_name, "detailClassName": s_name
                        })
    
    rakuten_df = pd.DataFrame(records)
    
    # gazetteer-of-japan.csvã®èª­ã¿è¾¼ã¿
    try:
        gaz_df = pd.read_csv("gazetteer-of-japan.csv")[["kanji", "lat", "lng"]]
    except Exception as e:
        print(f"âš ï¸ CSVèª­ã¿è¾¼ã¿è­¦å‘Š: {e}")
        gaz_df = pd.DataFrame(columns=["kanji", "lat", "lng"])

    # ç·¯åº¦çµŒåº¦æƒ…å ±ã®ç´ä»˜ã‘
    def lookup_latlon(detail_name):
        if not detail_name: return None, None
        for name in str(detail_name).split("ãƒ»"):
            match = gaz_df[gaz_df["kanji"] == name]
            if not match.empty:
                return match.iloc[0]["lat"], match.iloc[0]["lng"]
        return None, None

    if not rakuten_df.empty:
        rakuten_df[["latitude", "longitude"]] = rakuten_df["detailClassName"].apply(
            lambda x: pd.Series(lookup_latlon(x))
        )
    
    return rakuten_df, gaz_df

rakuten_df, gaz_df = initialize_data()

# --- 3. æ¤œç´¢ãƒ­ã‚¸ãƒƒã‚¯é–¢æ•° ---

def get_place_address(place_name):
    geolocator = Nominatim(user_agent="rakuten_search_bot")
    try:
        location = geolocator.geocode(place_name + ", Japan", timeout=10)
        return location.address if location else None
    except: return None

def find_nearest_rakuten_area(lat, lon, rakuten_df):
    min_dist, nearest = float("inf"), None
    for _, row in rakuten_df.iterrows():
        if pd.notnull(row["latitude"]):
            dist = geodesic((lat, lon), (row["latitude"], row["longitude"])).km
            if dist < min_dist:
                min_dist, nearest = dist, row.to_dict()
                nearest["matched_string"] = f"{dist:.2f}km"
    return nearest

def main_search(place_name, checkin=None, checkout=None, squeeze_cond=""):
    if not checkin: checkin = date.today().isoformat()
    if not checkout: checkout = (date.today() + timedelta(days=1)).isoformat()

    # ã‚¨ãƒªã‚¢ç‰¹å®š
    location = Nominatim(user_agent="rakuten_search_bot").geocode(place_name + ", Japan", timeout=10)
    if not location: return pd.DataFrame()
    match = find_nearest_rakuten_area(location.latitude, location.longitude, rakuten_df)
    
    params = {
        "applicationId": RAKUTEN_APP_ID,
        "format": "json",
        "checkinDate": checkin, "checkoutDate": checkout,
        "middleClassCode": match["middleClassCode"],
        "smallClassCode": match["smallClassCode"],
        "detailClassCode": match["detailClassCode"],
        "squeezeCondition": squeeze_cond
    }

    res = requests.get("https://app.rakuten.co.jp/services/api/Travel/VacantHotelSearch/20170426", params=params)
    if res.status_code != 200: return pd.DataFrame()

    hotels = res.json().get("hotels", [])
    plans = []
    for h in hotels:
        info = h["hotel"][0]["hotelBasicInfo"]
        rooms = h["hotel"][1].get("roomInfo", [])
        for i in range(0, len(rooms), 2):
            basic = rooms[i].get("roomBasicInfo", {})
            price = rooms[i+1].get("dailyCharge", {}).get("total")
            if price:
                plans.append({
                    "ä¼šå ´": place_name, "ãƒã‚§ãƒƒã‚¯ã‚¤ãƒ³": checkin, "ãƒ›ãƒ†ãƒ«å": info["hotelName"],
                    "æ–™é‡‘": int(price), "äºˆç´„URL": basic.get("reserveUrl")
                })
    return pd.DataFrame(plans)

# --- 4. å®Ÿè¡Œå‡¦ç† ---

# ã“ã ã‚ã‚Šæ¡ä»¶ã®å‡¦ç†
condition_map = {"ç¦ç…™": "kinen", "ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆ": "internet", "å¤§æµ´å ´": "daiyoku", "æ¸©æ³‰": "onsen", "æœé£Ÿä»˜ã": "breakfast", "å¤•é£Ÿä»˜ã": "dinner"}
squeeze_cond = ",".join([condition_map[c.strip()] for c in COND_INPUT.split(",") if c.strip() in condition_map])

# ä¼šå ´ãƒªã‚¹ãƒˆã®å‡¦ç†
venue_list = []
for line in PLACE_INPUT.splitlines():
    if not line.strip(): continue
    parts = [p.strip() for p in line.split(",")]
    if len(parts) >= 2:
        in_dt = datetime.strptime(parts[1], "%Y-%m-%d")
        out_dt = (in_dt + timedelta(days=1)).strftime("%Y-%m-%d")
        venue_list.append({"place": parts[0], "checkin": parts[1], "checkout": out_dt})
    else:
        venue_list.append({"place": parts[0]})

# ä¸€æ‹¬æ¤œç´¢
all_results = []
for v in venue_list:
    print(f"ğŸ” æ¤œç´¢ä¸­: {v['place']}")
    res_df = main_search(v["place"], v.get("checkin"), v.get("checkout"), squeeze_cond)
    if not res_df.empty: all_results.append(res_df)

if all_results:
    final_df = pd.concat(all_results).sort_values("æ–™é‡‘")
    print("\n### ğŸ¨ æ¤œç´¢çµæœä¸€è¦§")
    print(final_df.to_markdown(index=False))
    final_df.to_csv("result.csv", index=False, encoding="utf-8-sig")
else:
    print("âŒ ç©ºå®¤ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
